{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "07M8d6s2nPMm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, losses\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09yof9D_nla_"
      },
      "outputs": [],
      "source": [
        "# This code was used in Colab\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp \"/content/drive/My Drive/airbus_train.zip\" \"airbus_train.zip\"\n",
        "!cp \"/content/drive/My Drive/airbus_test.zip\" \"airbus_test.zip\"\n",
        "!cp \"/content/drive/My Drive/train_ship_segmentations_v2.csv\" \"train_ship_segmentations_v2.csv\"\n",
        "\n",
        "! mkdir airbus\n",
        "! unzip airbus_train.zip -d airbus\n",
        "\n",
        "! mkdir airbus_test\n",
        "! unzip airbus_test.zip -d airbus_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RODiR6qgnnDA"
      },
      "outputs": [],
      "source": [
        "#Reading a csv file that contains train_ship_segmentations\n",
        "df = pd.read_csv('train_ship_segmentations_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nTzUlkMinpX0"
      },
      "outputs": [],
      "source": [
        "#Define local variables\n",
        "TRAIN_PATH = '/content/airbus'\n",
        "TEST_PATH = '/content/airbus_test'\n",
        "CHECKPOINT_FILEPATH = '/content/unet.h5'\n",
        "\n",
        "train_files_name = [f for f in os.listdir(TRAIN_PATH) if f.endswith('.jpg')]\n",
        "test_files_name = [f for f in os.listdir(TEST_PATH) if f.endswith('.jpg')]\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "IMAGE_SIZE = (192, 192)\n",
        "ORIG_IMAGE_SIZE = (768, 768)\n",
        "BUFFER_SIZE = 500\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "TRAIN_LENGTH = len(train_files_name)\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_LENGTH = int(len(test_files_name) * 0.7)\n",
        "VALIDATION_STEPS = VALIDATION_LENGTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "TEST_LENGTH = len(test_files_name) - VALIDATION_LENGTH\n",
        "\n",
        "METRIC = 'val_loss'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qnQ7zPLToYWV"
      },
      "outputs": [],
      "source": [
        "def rle_decode(mask_rle, shape):\n",
        "    \"\"\"\n",
        "    Decode a run-length encoded (RLE) mask and return the corresponding binary mask.\n",
        "\n",
        "    :param mask_rle: Run-length encoded string representing the mask.\n",
        "    :param shape: Tuple representing the shape of the target binary mask (height, width).\n",
        "\n",
        "    :return: Binary mask as a NumPy array.\n",
        "    \"\"\"\n",
        "    # Initialize an array of zeros with the shape of the target binary mask\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "\n",
        "    # Check if the input is a non-empty string\n",
        "    if isinstance(mask_rle, str):\n",
        "        # Split the RLE string into starts and lengths\n",
        "        s = mask_rle.split()\n",
        "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "\n",
        "        # Adjust starts to zero-based indexing\n",
        "        starts -= 1\n",
        "\n",
        "        # Calculate ends based on starts and lengths\n",
        "        ends = starts + lengths\n",
        "\n",
        "        # Set the corresponding pixels in the array to 1 based on RLE information\n",
        "        for lo, hi in zip(starts, ends):\n",
        "            img[lo:hi] = 1\n",
        "\n",
        "    # Reshape the 1D array to the specified shape and transpose\n",
        "    img = img.reshape(shape).T\n",
        "\n",
        "    # Add an extra dimension to represent the channel (usually for grayscale images)\n",
        "    return np.expand_dims(img, axis=-1)\n",
        "\n",
        "df['EncodedPixels'] = df['EncodedPixels'].fillna('')\n",
        "\n",
        "all_masks = df.groupby(by='ImageId')['EncodedPixels'].agg(lambda seq: ' '.join(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s-PBXrOHo_3N"
      },
      "outputs": [],
      "source": [
        "def resize(img, mask):\n",
        "    \"\"\"\n",
        "    Resize the image and mask to the specified target size.\n",
        "\n",
        "    :param img: Input image.\n",
        "    :param mask: Input mask.\n",
        "    :return: Resized image and mask.\n",
        "    \"\"\"\n",
        "\n",
        "    img = tf.image.resize(img, IMAGE_SIZE, method=\"nearest\")\n",
        "    mask = tf.image.resize(mask, IMAGE_SIZE, method=\"nearest\")\n",
        "\n",
        "    return img, mask\n",
        "\n",
        "def flip(img, mask):\n",
        "    \"\"\"\n",
        "    Flip the image and mask horizontally or vertically with a certain probability.\n",
        "\n",
        "    :param img: Input image.\n",
        "    :param mask: Input mask.\n",
        "    :return: Flipped image and mask.\n",
        "    \"\"\"\n",
        "\n",
        "    # Flip left-right with a probability greater than 0.5\n",
        "    if np.random.uniform() > 0.5:\n",
        "        img = tf.image.flip_left_right(img[np.newaxis])[0]\n",
        "        mask = tf.image.flip_left_right(mask[np.newaxis])[0]\n",
        "\n",
        "    # Flip up-down with a probability greater than 0.5\n",
        "    if np.random.uniform() > 0.5:\n",
        "        img = tf.image.flip_up_down(img[np.newaxis])[0]\n",
        "        mask = tf.image.flip_up_down(mask[np.newaxis])[0]\n",
        "\n",
        "    return np.array(img), np.array(mask)\n",
        "\n",
        "def normalization(img):\n",
        "    \"\"\"\n",
        "    Normalize the pixel values of the image to the range [0, 1].\n",
        "\n",
        "    :param img: Input image.\n",
        "    :return: Normalized image.\n",
        "    \"\"\"\n",
        "\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "def load_image_train(image, mask):\n",
        "    \"\"\"\n",
        "    Preprocess and augment training images and masks.\n",
        "\n",
        "    :param image: Input image.\n",
        "    :param mask: Input mask.\n",
        "    :return: Processed and augmented image and mask.\n",
        "    \"\"\"\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "\n",
        "    image, mask = resize(image, mask)\n",
        "    image = normalization(image)\n",
        "    image, mask = flip(image, mask)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9sjWELBoot0H"
      },
      "outputs": [],
      "source": [
        "# Generator function to load images and masks for training or testing\n",
        "def dataset_generator(image_file_names, path):\n",
        "    \"\"\"\n",
        "    Generates preprocessed image and mask pairs for a given set of image file names.\n",
        "\n",
        "    :param image_file_names: List of image file names.\n",
        "    :param path: Path to the directory containing the images.\n",
        "    :return: Yield preprocessed image and mask pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    for image_name in image_file_names:\n",
        "        image_path = os.path.join(path, image_name)\n",
        "\n",
        "        # Load image using target size specified by IMAGE_SIZE\n",
        "        image = load_img(image_path, target_size=IMAGE_SIZE)\n",
        "\n",
        "        # Decode mask using the run-length encoding (RLE) and original image size\n",
        "        mask = rle_decode(all_masks.loc[image_name], ORIG_IMAGE_SIZE)\n",
        "\n",
        "        # Apply preprocessing and augmentation to image and mask\n",
        "        image, mask = load_image_train(image, mask)\n",
        "\n",
        "        # Yield the processed image and mask for each iteration\n",
        "        yield image, mask\n",
        "\n",
        "# Generator function for the training dataset\n",
        "def train_generator():\n",
        "    \"\"\"\n",
        "    Generator function for the training dataset.\n",
        "\n",
        "    :return: Yield preprocessed image and mask pairs for training.\n",
        "    \"\"\"\n",
        "\n",
        "    return dataset_generator(train_files_name, TRAIN_PATH)\n",
        "\n",
        "# Generator function for the test dataset\n",
        "def test_generator():\n",
        "    \"\"\"\n",
        "    Generator function for the test dataset.\n",
        "\n",
        "    :return: Yield preprocessed image and mask pairs for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    return dataset_generator(test_files_name, TEST_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EqBODmfkovut"
      },
      "outputs": [],
      "source": [
        "def dice_coeff(y_true, y_pred, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute the dice coefficient between the true and predicted binary masks.\n",
        "\n",
        "    :param y_true: True binary mask.\n",
        "    :param y_pred: Predicted binary mask.\n",
        "    :param smooth: Smoothing factor to avoid division by zero.\n",
        "    :return: Dice coefficient.\n",
        "    \"\"\"\n",
        "\n",
        "    y_true_f = tf.cast(y_true, tf.float32)\n",
        "    y_pred_f = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the dice loss between the true and predicted binary masks.\n",
        "\n",
        "    :param y_true: True binary mask.\n",
        "    :param y_pred: Predicted binary mask.\n",
        "    :return: Dice loss.\n",
        "    \"\"\"\n",
        "\n",
        "    return 1 - dice_coeff(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the combination of binary crossentropy (BCE) and Dice loss.\n",
        "\n",
        "    :param y_true: True binary mask.\n",
        "    :param y_pred: Predicted binary mask.\n",
        "    :return: Combined loss.\n",
        "    \"\"\"\n",
        "\n",
        "    # Combine binary crossentropy and dice loss\n",
        "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QaPcIld0naG_"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "    \"\"\"\n",
        "    Double convolution block with specified number of filters.\n",
        "\n",
        "    :param x: Input tensor.\n",
        "    :param n_filters: Number of filters.\n",
        "    :return: Output tensor after two convolution operations.\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\", kernel_initializer='random_normal')(x)\n",
        "    x = layers.Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\", kernel_initializer='random_normal')(x)\n",
        "    return x\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    \"\"\"\n",
        "    Downsample block with double convolution, max pooling, and dropout.\n",
        "\n",
        "    :param x: Input tensor.\n",
        "    :param n_filters: Number of filters.\n",
        "    :return: Feature tensor after double convolution, and downsampled tensor.\n",
        "    \"\"\"\n",
        "    f = double_conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.3)(p)\n",
        "    return f, p\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    \"\"\"\n",
        "    Upsample block with transposed convolution, concatenation, dropout, and double convolution.\n",
        "\n",
        "    :param x: Input tensor.\n",
        "    :param conv_features: Features from the corresponding downsample block.\n",
        "    :param n_filters: Number of filters.\n",
        "    :return: Output tensor after upsampling.\n",
        "    \"\"\"\n",
        "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "    x = layers.concatenate([x, conv_features])\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = double_conv_block(x, n_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet_model():\n",
        "    \"\"\"\n",
        "    Build the U-Net model for semantic segmentation.\n",
        "\n",
        "    :return: U-Net model.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=(*IMAGE_SIZE, 3))\n",
        "\n",
        "    # Downsample blocks\n",
        "    f1, p1 = downsample_block(inputs, 16)\n",
        "    f2, p2 = downsample_block(p1, 32)\n",
        "    f3, p3 = downsample_block(p2, 64)\n",
        "\n",
        "    # Bottleneck layer\n",
        "    bottleneck = double_conv_block(p3, 128)\n",
        "\n",
        "    # Upsample blocks\n",
        "    u3 = upsample_block(bottleneck, f3, 64)\n",
        "    u2 = upsample_block(u3, f2, 32)\n",
        "    u1 = upsample_block(u2, f1, 16)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(u1)\n",
        "\n",
        "    # Create and return the U-Net model\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "    return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RO7E89nrnaJX"
      },
      "outputs": [],
      "source": [
        "# Create tf datasets using the generator functions\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    train_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),  # Assuming RGB images\n",
        "        tf.TensorSpec(shape=(*IMAGE_SIZE, 1), dtype=tf.float32),  # Assuming single-channel masks\n",
        "    )\n",
        ")\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    test_generator,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(*IMAGE_SIZE, 1), dtype=tf.float32),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prepare batches for training, validation, and testing\n",
        "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = test_dataset.take(VALIDATION_LENGTH).batch(BATCH_SIZE)\n",
        "test_batches = test_dataset.skip(VALIDATION_LENGTH).take(TEST_LENGTH).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcrT3X9VnaLw"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the U-Net model\n",
        "unet_model = build_unet_model()\n",
        "\n",
        "# Compile the model with Adam optimizer, BCE + Dice loss, and Dice coefficient as a metric\n",
        "unet_model.compile(optimizer='adam',\n",
        "                   loss=bce_dice_loss,\n",
        "                   metrics=[dice_coeff])\n",
        "\n",
        "# Define a ModelCheckpoint callback to save the best model during training\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=CHECKPOINT_FILEPATH,\n",
        "    monitor=METRIC,\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# Define an EarlyStopping callback to stop training early if the loss doesn't improve\n",
        "earlystop = EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "# List of callbacks to be used during training\n",
        "callbacks_list = [checkpoint, earlystop]\n",
        "\n",
        "# Train the model using the training and validation datasets\n",
        "model_history = unet_model.fit(train_batches,\n",
        "                               validation_data=validation_batches,\n",
        "                               epochs=NUM_EPOCHS,\n",
        "                               steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                               validation_steps=VALIDATION_STEPS,\n",
        "                               callbacks=callbacks_list)\n",
        "\n",
        "print(unet_model.evaluate(test_batches))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Or7miVDnaOH"
      },
      "outputs": [],
      "source": [
        "#Optional\n",
        "# Plot the training and validation dice coefficients\n",
        "plt.plot(model_history.history['dice_coeff'], label='Train')\n",
        "plt.plot(model_history.history['val_dice_coeff'], label='Validation')\n",
        "plt.title('Model Dice Coefficient')\n",
        "plt.ylabel('Dice Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation losses\n",
        "plt.plot(model_history.history['loss'], label='Train')\n",
        "plt.plot(model_history.history['val_loss'], label='Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
